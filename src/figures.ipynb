{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/payamsadeghishabestari/virtual_envs/.venv/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "import mne\n",
    "from nilearn.plotting import plot_connectome\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import learn_graph\n",
    "from tqdm.notebook import tqdm\n",
    "from pingouin import intraclass_corr\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.manifold import MDS\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import mannwhitneyu\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### fig 1_A ######\n",
    "fname = Path.cwd().parent / \"data\" / \"graph_comparison_2.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "vals = [0.25, 0.5, 1, 1.5]\n",
    "df = df.query(\"alpha in @vals and beta in @vals\")\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "g = sns.FacetGrid(df, col=\"frequency_range\", row=\"alpha\", hue=\"beta\", height=2.5, aspect=1.3, palette=\"YlGnBu_d\", legend_out=True)\n",
    "kwargs = {\"markersize\": 2.5, \"lw\": 2}\n",
    "g.map_dataframe(sns.pointplot, x=\"times_used\", y=\"PDiv\", **kwargs)\n",
    "g.set(xticklabels=[], title=\"\", ylabel=\"\", xlabel=\"\")\n",
    "legend_kwargs = {\"bbox_to_anchor\": (0.5, 0.7, 0.5, 0.5)}\n",
    "g.add_legend(**legend_kwargs)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"PDiv.pdf\")\n",
    "\n",
    "###### fig 1_B ######\n",
    "fname = Path.cwd().parent / \"data\" / \"graph_comparison_2.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "vals = [0.25, 0.5, 1, 1.5]\n",
    "df = df.query(\"alpha in @vals and beta in @vals\")\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "g = sns.FacetGrid(df, col=\"frequency_range\", row=\"alpha\", hue=\"beta\", height=2.5, aspect=1.3, palette=\"YlGnBu_d\", legend_out=True)\n",
    "kwargs = {\"markersize\": 2.5, \"lw\": 2}\n",
    "g.map_dataframe(sns.pointplot, x=\"times_used\", y=\"euc_dist\", **kwargs)\n",
    "g.set(xticklabels=[], title=\"\", ylabel=\"\", xlabel=\"\")\n",
    "legend_kwargs = {\"bbox_to_anchor\": (0.5, 0.7, 0.5, 0.5)}\n",
    "g.add_legend(**legend_kwargs)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"euc_dist.pdf\")\n",
    "\n",
    "###### fig 1_C ######\n",
    "fname = Path.cwd().parent / \"data\" / \"df_diff.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "vals = [1, 1.5]\n",
    "df = df.query(\"alpha in @vals and beta in @vals\")\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "cl1, cl2 = sns.color_palette(\"YlGnBu_d\")[3], sns.color_palette(\"YlGnBu_d\")[5] \n",
    "g = sns.FacetGrid(df, col=\"frequency_range\", row=\"alpha\", hue=\"beta\", height=2.5, aspect=1.7, palette=[cl1, cl2], legend_out=True)\n",
    "kwargs = {\"markersize\": 2.5, \"lw\": 2}\n",
    "g.map_dataframe(sns.pointplot, x=\"times_used\", y=\"PDiv\", **kwargs)\n",
    "g.set(xticklabels=[], title=\"\", ylabel=\"\", xlabel=\"\")\n",
    "legend_kwargs = {\"bbox_to_anchor\": (0.5, 0.6, 0.5, 0.5)}\n",
    "g.add_legend(**legend_kwargs)\n",
    "def add_hline(data, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    ax.axhline(0, color='r', linestyle='--', linewidth=2)\n",
    "g.map_dataframe(add_hline)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"PDiv_dist_hline.pdf\")\n",
    "\n",
    "###### fig 1_D ######\n",
    "fname = Path.cwd().parent / \"data\" / \"df_diff.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "vals = [1, 1.5]\n",
    "df = df.query(\"alpha in @vals and beta in @vals\")\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "cl1, cl2 = sns.color_palette(\"YlGnBu_d\")[3], sns.color_palette(\"YlGnBu_d\")[5] \n",
    "g = sns.FacetGrid(df, col=\"frequency_range\", row=\"alpha\", hue=\"beta\", height=2.5, aspect=1.7, palette=[cl1, cl2], legend_out=True)\n",
    "kwargs = {\"markersize\": 2.5, \"lw\": 2}\n",
    "g.map_dataframe(sns.pointplot, x=\"times_used\", y=\"euc_dist\", **kwargs)\n",
    "g.set(xticklabels=[], title=\"\", ylabel=\"\", xlabel=\"\")\n",
    "legend_kwargs = {\"bbox_to_anchor\": (0.5, 0.6, 0.5, 0.5)}\n",
    "g.add_legend(**legend_kwargs)\n",
    "def add_hline(data, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    ax.axhline(0, color='r', linestyle='--', linewidth=2)\n",
    "g.map_dataframe(add_hline)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"euc_dist_hline.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### fig 2_A ######\n",
    "fname = Path.cwd().parent / \"data\" / \"identifiability_no_subtract.pkl\"\n",
    "with open(fname, 'rb') as file:\n",
    "    im_dict = pickle.load(file)\n",
    "\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11, 5))\n",
    "for ax, title in zip(axs, [\"alpha\", \"gamma\"]):\n",
    "    im_matrix = im_dict[title][\"aparc\"][1]\n",
    "    sns.heatmap(im_matrix, cmap=cmap, vmax=1, center=0.5,\n",
    "                square=True, linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "    ax.axvline(x=23, ymin=0, ymax=1, color=\"k\", linewidth=2)\n",
    "    ax.axhline(y=23, xmin=0, xmax=1, color=\"k\", linewidth=2)\n",
    "\n",
    "    ax.set(xticks=[], yticks=[], title=title)\n",
    "\n",
    "n_controls = 23\n",
    "cl1 = sns.cubehelix_palette(10, rot=2.5, light=.7, reverse=True)[9]\n",
    "cl2 = sns.cubehelix_palette(10, rot=-2*np.pi/10, light=.7, reverse=True)[1]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11, 3))\n",
    "kwargs = {\"linewidth\": 2}\n",
    "for ax, title in zip(axs, [\"alpha\", \"gamma\"]):\n",
    "    im_matrix = im_dict[title][\"aparc\"][1]\n",
    "    diagonal_values = np.diag(im_matrix)\n",
    "    off_diagonal_averages = (np.sum(im_matrix, axis=1) - diagonal_values) / (im_matrix.shape[1] - 1)\n",
    "    im_diff = diagonal_values - off_diagonal_averages\n",
    "    datas = [im_diff[:n_controls], im_diff[n_controls:]]\n",
    "    for data, label, color in zip(datas, [\"Controls\", \"Cases\"], [cl1, cl2]):\n",
    "        sns.kdeplot(data=data, color=color, fill=True, common_norm=True, ax=ax, alpha=0.3, label=label, legend=False, **kwargs)\n",
    "    ax.legend(frameon=False)\n",
    "    ax.spines[[\"right\", \"left\", \"top\"]].set_visible(False)\n",
    "    ax.set(xlim=[0.1, 0.8], yticks=[], ylabel=\"\", title=title)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(11, 3))\n",
    "kwargs = {\"linewidth\": 2}\n",
    "for ax, title in zip(axs, [\"alpha\", \"gamma\"]):\n",
    "    im_matrix = im_dict[title][\"aparc\"][1]\n",
    "    diagonal_values = np.diag(im_matrix)\n",
    "    off_diagonal_averages = (np.sum(im_matrix, axis=1) - diagonal_values) / (im_matrix.shape[1] - 1)\n",
    "    im_diff = diagonal_values - off_diagonal_averages\n",
    "    datas = [im_diff[:n_controls], im_diff[n_controls:]]\n",
    "    stat, p_val = ttest_ind(datas[0], datas[1],\n",
    "                                    permutations=0, random_state=42)\n",
    "    print(p_val)\n",
    "    sns.boxplot(data=datas, dodge=True, orient=\"h\", palette=[cl1, cl2], fill=False, width=0.8, gap=0.01, linewidth=2, ax=ax)\n",
    "    sns.stripplot(data=datas, dodge=True, orient=\"h\", palette=[cl1, cl2], ax=ax)\n",
    "    ax.legend(frameon=False)\n",
    "    ax.spines[[\"right\", \"left\", \"top\"]].set_visible(False)\n",
    "    ax.set(xlim=[0.1, 0.8], yticks=[], ylabel=\"\", title=title)\n",
    "\n",
    "###### fig 2_B ######\n",
    "fname = Path.cwd().parent / \"data\" / \"ranks.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "color_1 = sns.cubehelix_palette(10, rot=4.5, light=.7, reverse=True)[2]\n",
    "color_2 = sns.cubehelix_palette(10, rot=8.5, light=.7, reverse=True)[8]\n",
    "g = sns.FacetGrid(df, col=\"freq_band\", row=\"group\", hue=\"method\", height=2.5, palette=[color_1, color_2], aspect=1.7, legend_out=True)\n",
    "kwargs = {\"element\": \"step\", \"discrete\": True, \"multiple\": \"dodge\", \"fill\": True, \"stat\": \"percent\"}\n",
    "g.map(sns.histplot, \"rank\", **kwargs)\n",
    "legend_kwargs = {\"bbox_to_anchor\": (0.5, 0.6, 0.5, 0.5)}\n",
    "g.add_legend(**legend_kwargs)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"ranks.pdf\")\n",
    "\n",
    "###### fig 2_C ######\n",
    "def plot_gaussian_ellipse(mean, cov, ax, n_std=2.0, **kwargs):\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "    theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "    width, height = 2 * n_std * np.sqrt(vals)\n",
    "    ellip = Ellipse(xy=mean, width=width, height=height, angle=theta, **kwargs)\n",
    "    ax.add_patch(ellip)\n",
    "\n",
    "for title in [\"alpha\", \"gamma\"]:   \n",
    "    im_matrix = im_dict[title][\"aparc\"][1]\n",
    "    s_col = cosine_similarity(im_matrix.T)\n",
    "    s_row = cosine_similarity(im_matrix)\n",
    "    sim_matrix = 0.5 * (s_col + s_row)\n",
    "    mds = MDS(n_components=2, dissimilarity='precomputed', random_state=0)\n",
    "    X_2d = mds.fit_transform(1 - sim_matrix)\n",
    "    diagonal_values = np.diag(im_matrix)\n",
    "    off_diagonal_averages = (np.sum(im_matrix, axis=1) - diagonal_values) / (im_matrix.shape[1] - 1)\n",
    "    im_diff = diagonal_values - off_diagonal_averages\n",
    "    spectral = SpectralClustering(n_clusters=3, affinity=\"precomputed\", random_state=42)\n",
    "    clusters = spectral.fit_predict(sim_matrix)\n",
    "\n",
    "    cl1 = sns.color_palette(\"blend:#7AB,#EDA\", as_cmap=False).as_hex()[3]\n",
    "    cl2 = sns.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False).as_hex()[3]\n",
    "    cl3 = sns.color_palette(\"dark:#5A9_r\", as_cmap=False).as_hex()[3]\n",
    "    color_mapping = {0: cl1, 1: cl2, 2: cl3}\n",
    "    palette_color = ['#1f77b4', '#d62728'] \n",
    "    colors = ['#1f77b4'] * 23 + ['#d62728'] * 18\n",
    "    colors_clu = np.array([color_mapping[value] for value in clusters])\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(3.5, 7), layout=\"constrained\") \n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=colors, size=im_diff, sizes=(20, 400), palette=palette_color, legend=False, ax=axs[0])\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=colors_clu, size=im_diff, sizes=(20, 500), palette=[cl1, cl2, cl3], legend=False, ax=axs[1])\n",
    "\n",
    "    cl1_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cl1, markersize=10, label='Cluster 1')\n",
    "    cl2_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cl2, markersize=10, label='Cluster 2')\n",
    "    cl3_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=cl3, markersize=10, label='Cluster 3')\n",
    "    cl4_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=palette_color[0], markersize=10, label='Controls')\n",
    "    cl5_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=palette_color[1], markersize=10, label='Cases')\n",
    "    [ax.spines[[\"top\", \"right\"]].set_visible(False) for ax in axs]\n",
    "\n",
    "    for cluster, cl in zip(np.unique(clusters), [cl3, cl2, cl1]):\n",
    "        cluster_points = X_2d[clusters == cluster]\n",
    "        mean = np.mean(cluster_points, axis=0)\n",
    "        cov = np.cov(cluster_points.T)\n",
    "        plot_gaussian_ellipse(mean, cov, axs[1], n_std=2, alpha=0.12, color=cl)\n",
    "\n",
    "    fig.savefig(Path.cwd().parent / \"figures\" / f\"clusters_gl_{title}.pdf\")\n",
    "\n",
    "###### fig 2_D ######\n",
    "fname = Path.cwd().parent / \"data\" / \"identifiability_pli.pkl\"\n",
    "with open(fname, 'rb') as file:\n",
    "    im_pli_dict = pickle.load(file)\n",
    "\n",
    "palette_color = ['#1f77b4', '#d62728'] \n",
    "colors = ['#1f77b4'] * 23 + ['#d62728'] * 18\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(3.5, 7), layout=\"constrained\") # \n",
    "for title, ax in zip([\"alpha\", \"gamma\"], axs):\n",
    "\n",
    "    im_matrix = im_pli_dict[title]\n",
    "    s_col = cosine_similarity(im_matrix.T)\n",
    "    s_row = cosine_similarity(im_matrix)\n",
    "    sim_matrix = 0.5 * (s_col + s_row)\n",
    "    mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "    X_2d = mds.fit_transform(1 - sim_matrix)\n",
    "    diagonal_values = np.diag(im_matrix)\n",
    "    off_diagonal_averages = (np.sum(im_matrix, axis=1) - diagonal_values) / (im_matrix.shape[1] - 1)\n",
    "    im_diff = diagonal_values - off_diagonal_averages\n",
    "\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=colors, size=im_diff, sizes=(20, 400),\n",
    "                    palette=palette_color, legend=False, ax=ax)\n",
    "    ax.set_ylim(-0.9, 0.9)\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "fig.savefig(Path.cwd().parent / \"figures\" / \"clusters_pli.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### figure 3_A ###### (should be updated)\n",
    "label_names = [\"parahippocampal-lh\", \"superiorfrontal-lh\", \"superiorfrontal-rh\",\n",
    "                \"bankssts-lh\", \"rostralmiddlefrontal-lh\", \"frontalpole-lh\",\n",
    "                \"lateraloccipital-lh\", \"parsorbitalis-lh\", \"frontalpole-rh\"] \n",
    "\n",
    "brain_labels = np.array(mne.read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=False))\n",
    "lb_names = [lb.name for lb in brain_labels]\n",
    "idxs = np.array([lb_names.index(lb) for lb in label_names])\n",
    "lbs = list(brain_labels[idxs])\n",
    "cl1 = sns.cubehelix_palette(10, rot=2.5, light=.7, reverse=True)[9]\n",
    "cl2 = sns.cubehelix_palette(10, rot=-2*np.pi/10, light=.7, reverse=True)[1]\n",
    "cl3 = sns.cubehelix_palette(10, rot=4.5, light=.7, reverse=True)[3]\n",
    "cl4 = list(sns.color_palette(\"Reds\")[-1])\n",
    "cl5 = sns.cubehelix_palette(10, rot=4.5, light=.7, reverse=True)[2]\n",
    "cl6 = sns.cubehelix_palette(10, rot=8.5, light=.7, reverse=True)[8]\n",
    "cl7 = sns.cubehelix_palette(10, rot=8.5, light=.7, reverse=True)[0]\n",
    "cl8 = sns.cubehelix_palette(10, rot=1.5, light=.7, reverse=True)[2]\n",
    "cl9 = sns.cubehelix_palette(10, rot=4.5, light=.7, reverse=True)[5]\n",
    "colors = [cl1, cl2, cl3, cl4, cl5, cl6, cl7, cl8, cl9]\n",
    "\n",
    "brain_kwargs = dict(background=\"white\", surf=\"pial_semi_inflated\", cortex=[\"#b8b4ac\", \"#b8b4ac\"])\n",
    "\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"lh\", views=\"lateral\", **brain_kwargs)\n",
    "for lb, lb_name, color in zip(lbs, label_names, colors):\n",
    "    if lb.hemi == \"lh\":\n",
    "        brain.add_label(lb, hemi=\"lh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "brain_scr_1 = brain.screenshot()\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"rh\", views=\"lateral\", **brain_kwargs)\n",
    "for lb, lb_name, color in zip(lbs, label_names, colors):\n",
    "    if lb.hemi == \"rh\":\n",
    "        brain_scr_2 = brain.add_label(lb, hemi=\"rh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "brain_scr_2 = brain.screenshot()\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"lh\", views=\"medial\", **brain_kwargs)\n",
    "for lb, lb_name, color in zip(lbs, label_names, colors):\n",
    "    if lb.hemi == \"lh\":\n",
    "        brain_scr_3 = brain.add_label(lb, hemi=\"lh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "brain_scr_3 = brain.screenshot()\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"rh\", views=\"medial\", **brain_kwargs)\n",
    "for lb, lb_name, color in zip(lbs, label_names, colors):\n",
    "    if lb.hemi == \"rh\":\n",
    "        brain_scr_4 = brain.add_label(lb, hemi=\"rh\", color=color, borders=False, alpha=0.7)\n",
    "        \n",
    "brain_scr_4 = brain.screenshot()\n",
    "fig, axes = plt.subplots(2, 2, figsize=(9, 7))\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "for ax, brain in zip([axes[0][0], axes[0][1], axes[1][0], axes[1][1]], [brain_scr_1, brain_scr_2, brain_scr_3, brain_scr_4]):\n",
    "    nonwhite_pix = (brain != 255).any(-1)\n",
    "    nonwhite_row = nonwhite_pix.any(1)\n",
    "    nonwhite_col = nonwhite_pix.any(0)\n",
    "    cropped_screenshot = brain[nonwhite_row][:, nonwhite_col]\n",
    "    ax.imshow(cropped_screenshot)\n",
    "    ax.axis(\"off\")\n",
    "fig.savefig(Path.cwd().parent / \"figures\" / \"brains_aparc.pdf\")\n",
    "\n",
    "###### fig 3_B ######\n",
    "fname = Path.cwd().parent / \"data\" / \"connections.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "df_alpha_1 = df[(df[\"freq_band\"]==\"alpha\") & (df[\"label_2\"]==\"superiorfrontal-lh\")]\n",
    "df_alpha_2 = df[(df[\"freq_band\"]==\"alpha\") & (df[\"label_2\"]==\"superiorfrontal-rh\")]\n",
    "\n",
    "df_beta_1 = df[(df[\"freq_band\"]==\"beta\") & (df[\"label_2\"]==\"rostralmiddlefrontal-lh\")]\n",
    "df_beta_2 = df[(df[\"freq_band\"]==\"beta\") & (df[\"label_2\"]==\"lateraloccipital-lh\")]\n",
    "\n",
    "df_gamma_1 = df[(df[\"freq_band\"]==\"gamma\") & (df[\"label_2\"]==\"parsorbitalis-lh\")]\n",
    "df_gamma_2 = df[(df[\"freq_band\"]==\"gamma\") & (df[\"label_2\"]==\"superiorfrontal-lh\")]\n",
    "df_gamma_3 = df[(df[\"freq_band\"]==\"gamma\") & (df[\"label_2\"]==\"superiorfrontal-rh\")]\n",
    "\n",
    "dfs = [df_alpha_1, df_alpha_2, df_beta_1, df_beta_2, df_gamma_1, df_gamma_2, df_gamma_3]\n",
    "palette_color = ['#1f77b4', '#d62728']\n",
    "hue_order = [\"control\", \"case\"]\n",
    "\n",
    "\n",
    "for serie, title in zip([range(2), range(2, 4), range(4, 7)], [\"alpha\", \"beta\", \"gamma\"]):\n",
    "    if title == \"gamma\":\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(5, 3))\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(5, 3))\n",
    "    \n",
    "    for ax_idx, (idx, ax) in enumerate(zip(serie, axs)):\n",
    "        sns.boxplot(data=dfs[idx], x=\"group\", y=\"connection_strength\", hue=\"group\",\n",
    "                        hue_order=hue_order, palette=palette_color, fill=False, width=0.6,\n",
    "                        gap=0, linewidth=1.8, ax=ax)\n",
    "        sns.stripplot(data=dfs[idx], x=\"group\", y=\"connection_strength\", hue=\"group\", \n",
    "                        hue_order=hue_order, palette=palette_color, linewidth=0, size=3.5,\n",
    "                        edgecolor=None, ax=ax)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_ylabel(\"\")\n",
    "        ax.set_ylim([None, 0.04])\n",
    "        if ax_idx in [1, 2]:\n",
    "            ax.spines['left'].set_visible(False)\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    # fig.savefig(Path.cwd().parent / \"figures\" / f\"{title}.pdf\")\n",
    "\n",
    "dfs = [df_alpha_1, df_alpha_2, df_beta_1, df_beta_2, df_gamma_1, df_gamma_2, df_gamma_3]\n",
    "def plot_glass_brains(dfs, title):\n",
    "    ###### fig 3_C ######\n",
    "    labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc', subjects_dir=None, verbose=False)[:-1]\n",
    "    node_coords = []\n",
    "    for label in labels:\n",
    "        if label.hemi == 'lh':\n",
    "            hemi = 0\n",
    "        if label.hemi == 'rh':\n",
    "            hemi = 1\n",
    "        center_vertex = label.center_of_mass(subject='fsaverage', \n",
    "                                            restrict_vertices=False, \n",
    "                                            subjects_dir=None)\n",
    "        mni_pos = mne.vertex_to_mni(center_vertex, hemis=hemi,\n",
    "                                subject='fsaverage', subjects_dir=None)\n",
    "        node_coords.append(mni_pos)\n",
    "    node_coords = np.array(node_coords)\n",
    "    ticks = [lb.name for lb in labels]\n",
    "    matrix = np.zeros(shape=(len(labels), len(labels)))\n",
    "    for df in dfs:\n",
    "        idx1 = ticks.index(df[\"label_1\"].unique()[0])\n",
    "        idx2 = ticks.index(df[\"label_2\"].unique()[0])\n",
    "        matrix[idx1][idx2] = 1 \n",
    "\n",
    "    graph = matrix + matrix.T\n",
    "    custom_cmap = sns.cubehelix_palette(10, rot=-.45, light=.65, reverse=True, as_cmap=True)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(11, 3))\n",
    "    edge_kwargs = {\"lw\": 3}\n",
    "    plot_connectome(adjacency_matrix=graph, node_coords=node_coords, display_mode=\"lzry\", edge_cmap=custom_cmap,\n",
    "                    node_color='k', node_size=10, axes=ax, colorbar=False,\n",
    "                    edge_threshold=\"90%\", edge_kwargs=edge_kwargs)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(Path.cwd().parent / \"figures\" / f\"{title}_glass_brain_green.pdf\")\n",
    "\n",
    "for sub_dfs, title in zip([dfs[:2], dfs[2:4], dfs[4:]], [\"alpha\", \"beta\", \"gamma\"]):\n",
    "    plot_glass_brains(sub_dfs, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### fig 4_A ###### \n",
    "\n",
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_controls.npy\"\n",
    "icc_obs_controls = np.load(fname, allow_pickle=True)\n",
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_cases.npy\"\n",
    "icc_obs_cases = np.load(fname, allow_pickle=True)\n",
    "fname = Path.cwd().parent / \"data\" / \"surrogate_unspecific_group_10_random.npy\"\n",
    "icc_surr = np.load(fname, allow_pickle=True)\n",
    "\n",
    "## compute nodal brain fingerprint per group\n",
    "n_edges = 68\n",
    "p_values_control = np.zeros(shape=(n_edges, n_edges))\n",
    "p_values_case = np.zeros(shape=(n_edges, n_edges))\n",
    "\n",
    "for i in range(n_edges):\n",
    "    for j in range(n_edges):\n",
    "        count_extreme_1 = np.sum(icc_surr[:, i, j] >= icc_obs_controls[i, j])\n",
    "        p_values_control[i, j] = (count_extreme_1 + 1)  / (len(icc_surr) + 1) ## add +1\n",
    "\n",
    "        count_extreme_2 = np.sum(icc_surr[:, i, j] >= icc_obs_cases[i, j])\n",
    "        p_values_case[i, j] = (count_extreme_2 + 1) / (len(icc_surr) + 1) ## add +1\n",
    "\n",
    "threshold = 0.05\n",
    "binary_mask_control = (p_values_control < threshold).astype(int) # less and equal\n",
    "binary_mask_case = (p_values_case < threshold).astype(int) # less and equal\n",
    "\n",
    "sig_icc_control = icc_obs_controls * binary_mask_control\n",
    "sig_icc_case = icc_obs_cases * binary_mask_case\n",
    "\n",
    "df_icc_control = pd.DataFrame(icc_obs_cases).stack().reset_index()\n",
    "df_icc_control.rename(columns={\"level_0\" : \"lb-1\", \"level_1\": \"lb-2\", 0: \"ICC-val\"}, inplace=True)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pal = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "g = sns.relplot(data=df_icc_control, x=\"lb-1\", y=\"lb-2\", hue=\"ICC-val\",\n",
    "                palette=pal, hue_norm=(0, 1), sizes=(1, 1), legend=False,\n",
    "                height=5, aspect=1)\n",
    "g.ax.invert_yaxis()\n",
    "g.set(xlabel=\"\", ylabel=\"\", xticklabels=\"\", yticklabels=\"\")\n",
    "g.despine(top=True, right=True, left=True, bottom=True)\n",
    "g.ax.margins(0.02)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"icc_obs_cases.pdf\")\n",
    "\n",
    "###### fig 4_B ###### \n",
    "def plot_4_brains(bl_idxs, nodes_strength):\n",
    "    brain_labels = np.array(mne.read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=False))\n",
    "    brain_labels_sub = list(np.array(brain_labels[bl_idxs]))\n",
    "    nodes_strength_norm = (nodes_strength - nodes_strength.min()) / (nodes_strength.max() - nodes_strength.min())\n",
    "    brain_kwargs = dict(background=\"white\", surf=\"pial_semi_inflated\", cortex=[\"#b8b4ac\", \"#b8b4ac\"])\n",
    "\n",
    "    pal = sns.color_palette(\"ch:s=.25,rot=-.25\", as_cmap=False, n_colors=100).as_hex()\n",
    "    colors = [pal[int(value * (len(pal) - 1))] for value in nodes_strength_norm]\n",
    "\n",
    "    brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"lh\", views=\"lateral\", **brain_kwargs)\n",
    "    for lb, color in zip(brain_labels_sub, colors):\n",
    "        if lb.hemi == \"lh\":\n",
    "            brain.add_label(lb, hemi=\"lh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "    brain_scr_1 = brain.screenshot()\n",
    "    brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"rh\", views=\"lateral\", **brain_kwargs)\n",
    "    for lb, color in zip(brain_labels_sub, colors):\n",
    "        if lb.hemi == \"rh\":\n",
    "            brain_scr_2 = brain.add_label(lb, hemi=\"rh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "    brain_scr_2 = brain.screenshot()\n",
    "    brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"lh\", views=\"medial\", **brain_kwargs)\n",
    "    for lb, color in zip(brain_labels_sub, colors):\n",
    "        if lb.hemi == \"lh\":\n",
    "            brain_scr_3 = brain.add_label(lb, hemi=\"lh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "    brain_scr_3 = brain.screenshot()\n",
    "    brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"rh\", views=\"medial\", **brain_kwargs)\n",
    "    for lb, color in zip(brain_labels_sub, colors):\n",
    "        if lb.hemi == \"rh\":\n",
    "            brain_scr_4 = brain.add_label(lb, hemi=\"rh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "    brain_scr_4 = brain.screenshot()\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(9, 7))\n",
    "    fig.subplots_adjust(hspace=0.1)\n",
    "    for ax, brain in zip([axes[0][0], axes[0][1], axes[1][0], axes[1][1]], [brain_scr_1, brain_scr_2, brain_scr_3, brain_scr_4]):\n",
    "        nonwhite_pix = (brain != 255).any(-1)\n",
    "        nonwhite_row = nonwhite_pix.any(1)\n",
    "        nonwhite_col = nonwhite_pix.any(0)\n",
    "        cropped_screenshot = brain[nonwhite_row][:, nonwhite_col]\n",
    "        ax.imshow(cropped_screenshot)\n",
    "        ax.axis(\"off\")\n",
    "    \n",
    "    return fig, [bl.name for bl in brain_labels_sub]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function for plotting ellipse\n",
    "def plot_gaussian_ellipse(mean, cov, ax, n_std=2.0, **kwargs):\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    vals, vecs = vals[order], vecs[:, order]\n",
    "    theta = np.degrees(np.arctan2(*vecs[:, 0][::-1]))\n",
    "    width, height = 2 * n_std * np.sqrt(vals)\n",
    "    ellip = Ellipse(xy=mean, width=width, height=height, angle=theta, **kwargs)\n",
    "    ax.add_patch(ellip)\n",
    "\n",
    "## loading IM matrixes\n",
    "fname = Path.cwd().parent / \"data\" / \"identifiability_no_subtract.pkl\"\n",
    "with open(fname, 'rb') as file:\n",
    "    im_dict = pickle.load(file)\n",
    "\n",
    "## make the IM matrix symmetric\n",
    "labels = [\"control\"] * 23 + [\"case\"] * 18\n",
    "im_matrix = im_dict[\"alpha\"][\"aparc\"][1] # selecting alpha for now\n",
    "s_col = cosine_similarity(im_matrix.T)\n",
    "s_row = cosine_similarity(im_matrix)\n",
    "sim_matrix = 0.5 * (s_col + s_row)\n",
    "\n",
    "## clustering and plotting dendrogram\n",
    "Z = linkage(sim_matrix, method='ward')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "dendrogram(Z, p=30, labels=labels, ax=ax)\n",
    "ax.set(frame_on=False, yticks=[], title=\"Hierarchical Clustering Dendrogram\")\n",
    "\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "X_2d = mds.fit_transform(1 - sim_matrix)\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14, 4))\n",
    "criterion = \"maxclust\"\n",
    "m_values = range(2, 6)\n",
    "colors = [\"blue\"] * 23 + [\"red\"] * 18\n",
    "for m, ax in zip(m_values, axs):\n",
    "    clusters = fcluster(Z, m, criterion=criterion)\n",
    "    silh_hier_avg = silhouette_score(sim_matrix, clusters, metric='euclidean')\n",
    "    \n",
    "    for cluster in np.unique(clusters):\n",
    "        cluster_points = X_2d[clusters == cluster]\n",
    "        mean = np.mean(cluster_points, axis=0)\n",
    "        cov = np.cov(cluster_points.T)\n",
    "        ax.scatter(X_2d[:, 0], X_2d[:, 1], c=colors, s=15)\n",
    "        plot_gaussian_ellipse(mean, cov, ax, n_std=2, alpha=0.15, color=np.random.rand(3,))\n",
    "        ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "        if m != 2:\n",
    "            ax.set(yticks=[])\n",
    "        ax.set_title(f\"M = {m} \\n avg silhouette score = {round(silh_hier_avg, 4)}\", fontsize=9)\n",
    "\n",
    "blue_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Controls')\n",
    "red_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Cases')\n",
    "ax.legend(handles=[blue_patch, red_patch], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting the same for spectral clustering\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "X_2d = mds.fit_transform(1 - sim_matrix)\n",
    "\n",
    "m_values = range(2, 6)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(14, 4))\n",
    "for m, ax in zip(m_values, axs):\n",
    "    spectral = SpectralClustering(n_clusters=m, affinity=\"precomputed\", random_state=42)\n",
    "    clusters = spectral.fit_predict(sim_matrix)\n",
    "    silh_spect_avg = silhouette_score(sim_matrix, clusters, metric='euclidean')\n",
    "    \n",
    "    for cluster in np.unique(clusters):\n",
    "        cluster_points = X_2d[clusters == cluster]\n",
    "        mean = np.mean(cluster_points, axis=0)\n",
    "        cov = np.cov(cluster_points.T)\n",
    "        ax.scatter(X_2d[:, 0], X_2d[:, 1], c=colors, s=15)\n",
    "        plot_gaussian_ellipse(mean, cov, ax, n_std=2, alpha=0.15, color=np.random.rand(3,))\n",
    "        ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "        if m != 2:\n",
    "            ax.set(yticks=[])\n",
    "        ax.set_title(f\"M = {m} \\n avg silhouette score = {round(silh_spect_avg, 4)}\", fontsize=9)\n",
    "\n",
    "blue_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='blue', markersize=10, label='Controls')\n",
    "red_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Cases')\n",
    "ax.legend(handles=[blue_patch, red_patch], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## what if I use gaussian mixture in 1d and 2d with 3 components\n",
    "im_matrix = im_dict[title][\"aparc\"][1]\n",
    "diagonal_values = np.diag(im_matrix)\n",
    "off_diagonal_averages = (np.sum(im_matrix, axis=1) - diagonal_values) / (im_matrix.shape[1] - 1)\n",
    "im_diff = diagonal_values - off_diagonal_averages\n",
    "\n",
    "rnd = 42 # 1\n",
    "gmm = GaussianMixture(n_components=3, random_state=rnd)  \n",
    "gmm.fit(im_diff.reshape(-1, 1))\n",
    "print(f\"AIC: {round(gmm.aic(im_diff.reshape(-1, 1)), 2)}\")\n",
    "print(f\"BIC: {round(gmm.bic(im_diff.reshape(-1, 1)), 2)}\")\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "logprob = gmm.score_samples(x.reshape(-1, 1))\n",
    "pdf = np.exp(logprob)\n",
    "\n",
    "kwargs = {\"linewidth\": 2}\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "sns.kdeplot(im_diff, fill=True, color=\"black\", alpha=0.1, ax=ax, **kwargs)\n",
    "for mean, cov, weight in zip(gmm.means_, gmm.covariances_, gmm.weights_):\n",
    "    std = np.sqrt(cov)\n",
    "    component_pdf = weight * norm.pdf(x, mean, std)\n",
    "    ax.plot(x, component_pdf.T, linestyle='--', label=f'Component (mean={mean[0]:.2f})', **kwargs)\n",
    "\n",
    "ax.set(title = \"1D distribution of I_diff\", xlim=[0, 1])\n",
    "ax.legend(frameon=False)\n",
    "\n",
    "gmm = GaussianMixture(n_components=3, random_state=rnd) \n",
    "gmm.fit(X_2d)\n",
    "labels = [\"control\"] * 23 + [\"case\"] * 18\n",
    "means = gmm.means_\n",
    "covariances = gmm.covariances_\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=labels, palette=[\"blue\", \"red\"], s=50, edgecolor='k', legend=True, ax=ax)\n",
    "for mean, cov in zip(means, covariances):\n",
    "    plot_gaussian_ellipse(mean, cov, ax, n_std=2, alpha=0.15, color=np.random.rand(3,))\n",
    "\n",
    "ax.legend(frameon=False)\n",
    "ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "ax.set_title(\"2D distribution of I_diff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir1 = '/Users/payamsadeghishabestari/meg_gsp/stc_labels/tinmeg1'\n",
    "dir2 = '/Users/payamsadeghishabestari/meg_gsp/stc_labels/tinmeg3'\n",
    "\n",
    "sfreq = 250\n",
    "end_sample = 5 * 60 * sfreq \n",
    "dist_type = \"sqeuclidean\"\n",
    "alpha = 1\n",
    "step = 0.5\n",
    "max_iter = 10000\n",
    "rtol = 1e-16\n",
    "beta = 1\n",
    "freq_range = 'alpha'\n",
    "\n",
    "fnames = []\n",
    "for dir in [dir1, dir2]:\n",
    "    for filename in sorted(os.listdir(dir)): \n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f) and f.endswith(f'aparc_mean.npy') and freq_range in f:\n",
    "            fnames.append(f)\n",
    "\n",
    "graphs = []\n",
    "for fname in tqdm(fnames):\n",
    "    tcs = np.load(file=fname, allow_pickle=True)[:, :end_sample]\n",
    "    graph = learn_graph.log_degree_barrier(X=tcs, dist_type=dist_type,\n",
    "                                                alpha=alpha, beta=beta, step=step,\n",
    "                                                w0=None, maxit=max_iter, rtol=rtol,\n",
    "                                                retall=False)\n",
    "    graph = graph / np.linalg.norm(graph, 'fro')\n",
    "    graph[graph < 0.01 * np.max(graph)] = 0\n",
    "    graphs.append(graph)\n",
    "\n",
    "graphs = np.array(graphs)\n",
    "\n",
    "labels = mne.read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\",\n",
    "                                    subjects_dir=None, verbose=False)[:-1]\n",
    "node_coords = []\n",
    "for label in labels:\n",
    "    if label.hemi == 'lh': hemi = 0\n",
    "    if label.hemi == 'rh': hemi = 1\n",
    "    center_vertex = label.center_of_mass(subject=\"fsaverage\", \n",
    "                                        restrict_vertices=False, \n",
    "                                        subjects_dir=None)\n",
    "    mni_pos = mne.vertex_to_mni(center_vertex, hemis=hemi,\n",
    "                                subject=\"fsaverage\", subjects_dir=None)\n",
    "    node_coords.append(mni_pos)\n",
    "\n",
    "controls_array = np.array([i for i in range(23) if i not in {9, 19, 1, 18}])\n",
    "cases_array = np.array([i for i in range(23, 41) if i not in {36, 24, 31}])\n",
    "\n",
    "node_coords = np.array(node_coords)\n",
    "ticks = [lb.name for lb in labels]\n",
    "fig, axs = plt.subplots(2, 1, figsize=(11, 5))\n",
    "for ids, ax in zip([controls_array, cases_array], axs):\n",
    "    avg_graph = graphs[ids].mean(axis=0)\n",
    "    plot_connectome(adjacency_matrix=avg_graph, node_coords=node_coords,\n",
    "                    node_color='k', node_size=10, axes=ax,\n",
    "                    edge_threshold='98%')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## is MSD representation as a sort of ground truth? the answer is yes.\n",
    "mds = MDS(n_components=2, dissimilarity='precomputed', random_state=42)\n",
    "X_2d = mds.fit_transform(1 - sim_matrix)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "spectral = SpectralClustering(n_clusters=3, affinity=\"precomputed\", random_state=42)\n",
    "clusters = spectral.fit_predict(sim_matrix)\n",
    "\n",
    "# spectral = KMeans(n_clusters=3, random_state=5)\n",
    "# clusters = spectral.fit_predict(X_2d)\n",
    "\n",
    "color_mapping = {0: 'olive', 1: 'darkviolet', 2: 'coral'}\n",
    "point_idx = 31\n",
    "\n",
    "for cluster in np.unique(clusters):\n",
    "    cluster_points = X_2d[clusters == cluster]\n",
    "    mean = np.mean(cluster_points, axis=0)\n",
    "    cov = np.cov(cluster_points.T)\n",
    "    # colors = np.array([color_mapping[value] for value in clusters])\n",
    "    colors = [\"cyan\"] * 23 + [\"red\"] * 18\n",
    "    ax.scatter(X_2d[:, 0], X_2d[:, 1], c=colors, s=30)\n",
    "    ax.scatter(X_2d[point_idx, 0], X_2d[point_idx, 1], c=\"k\", s=30)\n",
    "    plot_gaussian_ellipse(mean, cov, ax, n_std=2, alpha=0.08, color=np.random.rand(3,))\n",
    "    ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "    if m != 2:\n",
    "        ax.set(yticks=[])\n",
    "    ax.set_title(f\"M = 3\", fontsize=9)\n",
    "\n",
    "cl1_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='olive', markersize=10, label='cluster_1')\n",
    "cl2_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='darkviolet', markersize=10, label='cluster_2')\n",
    "cl3_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='coral', markersize=10, label='cluster_3')\n",
    "\n",
    "ax.legend(handles=[cl1_patch, cl2_patch, cl3_patch], frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "straightforward ICC approach, coupled with a nice bootstrapping step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create test_retest FCs per subject\n",
    "dir1 = '/Users/payamsadeghishabestari/meg_gsp/stc_labels/tinmeg1'\n",
    "dir2 = '/Users/payamsadeghishabestari/meg_gsp/stc_labels/tinmeg3'\n",
    "freq_range = 'gamma'\n",
    "fnames = []\n",
    "for dir in [dir1, dir2]:\n",
    "    for filename in sorted(os.listdir(dir)): \n",
    "        f = os.path.join(dir, filename)\n",
    "        if os.path.isfile(f) and f.endswith(f'aparc_mean.npy') and freq_range in f:\n",
    "            fnames.append(f)\n",
    "\n",
    "n_controls = 23\n",
    "sfreq = 250\n",
    "end_sample = 5 * 60 * sfreq \n",
    "kwargs = {\n",
    "        \"dist_type\": \"sqeuclidean\",\n",
    "        \"alpha\": 1,\n",
    "        \"step\": 0.5,\n",
    "        \"maxit\": 10000,\n",
    "        \"rtol\": 1e-16,\n",
    "        \"beta\": 1,\n",
    "        \"w0\": None,\n",
    "        \"retall\": False\n",
    "        }\n",
    "\n",
    "graphs = []\n",
    "for fname in tqdm(fnames):\n",
    "    tcs_1 = np.load(file=fname, allow_pickle=True)[:, :int(end_sample/2)]\n",
    "    tcs_2 = np.load(file=fname, allow_pickle=True)[:, int(end_sample/2):end_sample]\n",
    "    graph_1 = learn_graph.log_degree_barrier(X=tcs_1, **kwargs)\n",
    "    graph_2 = learn_graph.log_degree_barrier(X=tcs_2, **kwargs)\n",
    "    graph_1 = graph_1 / np.linalg.norm(graph_1, 'fro')\n",
    "    graph_2 = graph_2 / np.linalg.norm(graph_2, 'fro')\n",
    "    graphs.append([graph_1, graph_2])\n",
    "\n",
    "graphs_control = np.array(graphs[:n_controls]) # the shape should be (23, 2, 68, 68)\n",
    "graphs_cases = np.array(graphs[n_controls:])\n",
    "n_edges = graphs_control.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## computing observed ICC for controls\n",
    "mask = np.triu(np.ones((n_edges, n_edges), dtype=bool), k=1)\n",
    "df_matrix = graphs_control[:, :, mask]\n",
    "icc_vals = []\n",
    "\n",
    "for edge_idx in range(df_matrix.shape[-1]):\n",
    "    df = pd.DataFrame(df_matrix[:,:,edge_idx])\n",
    "    df_long = df.stack().reset_index()\n",
    "    df_long.columns = ['measurements', 'judges', 'ratings']\n",
    "    df_long['measurements'] += 1  \n",
    "    df_long['judges'] += 1\n",
    "    icc_df = intraclass_corr(data=df_long, targets='measurements', raters='judges', ratings='ratings')\n",
    "    icc_val = icc_df.loc[icc_df['Type'] == 'ICC1', 'ICC'].values[0]\n",
    "    icc_vals.append(icc_val)\n",
    "\n",
    "icc_matrix = np.zeros(shape=(n_edges, n_edges))\n",
    "icc_matrix[np.triu_indices(n_edges, k=1)] = np.array([icc_vals])\n",
    "icc_obs_controls = icc_matrix + icc_matrix.T\n",
    "np.save(\"/Users/payamsadeghishabestari/codes/graph-learning/data/icc_obs_controls_gamma.npy\", np.array(icc_obs_controls))\n",
    "\n",
    "## computing observed ICC for cases\n",
    "mask = np.triu(np.ones((n_edges, n_edges), dtype=bool), k=1)\n",
    "df_matrix = graphs_cases[:, :, mask]\n",
    "icc_vals = []\n",
    "\n",
    "for edge_idx in range(df_matrix.shape[-1]):\n",
    "    df = pd.DataFrame(df_matrix[:,:,edge_idx])\n",
    "    df_long = df.stack().reset_index()\n",
    "    df_long.columns = ['measurements', 'judges', 'ratings']\n",
    "    df_long['measurements'] += 1  \n",
    "    df_long['judges'] += 1\n",
    "    icc_df = intraclass_corr(data=df_long, targets='measurements', raters='judges', ratings='ratings')\n",
    "    icc_val = icc_df.loc[icc_df['Type'] == 'ICC1', 'ICC'].values[0]\n",
    "    icc_vals.append(icc_val)\n",
    "\n",
    "icc_matrix = np.zeros(shape=(n_edges, n_edges))\n",
    "icc_matrix[np.triu_indices(n_edges, k=1)] = np.array([icc_vals])\n",
    "icc_obs_cases = icc_matrix + icc_matrix.T\n",
    "np.save(\"/Users/payamsadeghishabestari/codes/graph-learning/data/icc_obs_cases_gamma.npy\", np.array(icc_obs_cases))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create surrogate unspecific group\n",
    "n_bootstrap = 500\n",
    "n_selected = 10\n",
    "mask = np.triu(np.ones((n_edges, n_edges), dtype=bool), k=1)\n",
    "icc_matrixes = []\n",
    "\n",
    "for bootstrap in tqdm(range(n_bootstrap)):\n",
    "    ## make a correct form of matrix for dataframe\n",
    "    icc_vals = []\n",
    "    randam_subjects_1 = np.random.choice(range(len(graphs_control)), n_selected, replace=True)\n",
    "    randam_subjects_2 = np.random.choice(range(len(graphs_cases)), n_selected, replace=True)\n",
    "    df_matrix_1 = graphs_control[randam_subjects_1][:, :, mask] # shape (n_measurements, n_judges, n_edges)\n",
    "    df_matrix_2 = graphs_cases[randam_subjects_2][:, :, mask] # shape (n_measurements, n_judges, n_edges)\n",
    "    df_matrix = np.concatenate([df_matrix_1, df_matrix_2], axis=0)\n",
    "\n",
    "    ## make a dataframe for ICC and compute it\n",
    "    for edge_idx in range(df_matrix.shape[-1]):\n",
    "        df = pd.DataFrame(df_matrix[:,:,edge_idx])\n",
    "        df_long = df.stack().reset_index()\n",
    "        df_long.columns = ['measurements', 'judges', 'ratings']\n",
    "        df_long['measurements'] += 1  \n",
    "        df_long['judges'] += 1\n",
    "        icc_df = intraclass_corr(data=df_long, targets='measurements', raters='judges', ratings='ratings')\n",
    "        icc_val = icc_df.loc[icc_df['Type'] == 'ICC1', 'ICC'].values[0]\n",
    "        icc_vals.append(icc_val)\n",
    "\n",
    "    icc_matrix = np.zeros(shape=(n_edges, n_edges))\n",
    "    icc_matrix[np.triu_indices(n_edges, k=1)] = np.array([icc_vals])\n",
    "    icc_matrix = icc_matrix + icc_matrix.T\n",
    "    icc_matrixes.append(icc_matrix)\n",
    "\n",
    "np.save(\"/Users/payamsadeghishabestari/codes/graph-learning/data/surrogate_unspecific_group_10_random.npy\", np.array(icc_matrixes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you are interested in significant difference between controls and cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_controls.npy\"\n",
    "icc_obs_controls = np.load(fname, allow_pickle=True)\n",
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_cases.npy\"\n",
    "icc_obs_cases = np.load(fname, allow_pickle=True)\n",
    "fname = Path.cwd().parent / \"data\" / \"surrogate_unspecific_group_10_random.npy\"\n",
    "icc_surr = np.load(fname, allow_pickle=True)\n",
    "\n",
    "## compute nodal brain fingerprint per group\n",
    "p_values_control = np.zeros(shape=(n_edges, n_edges))\n",
    "p_values_case = np.zeros(shape=(n_edges, n_edges))\n",
    "\n",
    "for i in range(n_edges):\n",
    "    for j in range(n_edges):\n",
    "        count_extreme_1 = np.sum(icc_surr[:, i, j] >= icc_obs_controls[i, j])\n",
    "        p_values_control[i, j] = (count_extreme_1 + 1)  / (len(icc_surr) + 1) ## add +1\n",
    "\n",
    "        count_extreme_2 = np.sum(icc_surr[:, i, j] >= icc_obs_cases[i, j])\n",
    "        p_values_case[i, j] = (count_extreme_2 + 1) / (len(icc_surr) + 1) ## add +1\n",
    "\n",
    "threshold = 0.05\n",
    "binary_mask_control = (p_values_control < threshold).astype(int) # less and equal\n",
    "binary_mask_case = (p_values_case < threshold).astype(int) # less and equal\n",
    "\n",
    "sig_icc_control = icc_obs_controls * binary_mask_control\n",
    "sig_icc_case = icc_obs_cases * binary_mask_case\n",
    "\n",
    "df_icc_control = pd.DataFrame(sig_icc_case).stack().reset_index()\n",
    "df_icc_control.rename(columns={\"level_0\" : \"lb-1\", \"level_1\": \"lb-2\", 0: \"ICC-val\"}, inplace=True)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pal = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "g = sns.relplot(data=df_icc_control, x=\"lb-1\", y=\"lb-2\", hue=\"ICC-val\",\n",
    "                palette=pal, hue_norm=(0, 1), sizes=(1, 1), legend=False,\n",
    "                height=5, aspect=1)\n",
    "g.ax.invert_yaxis()\n",
    "g.set(xlabel=\"\", ylabel=\"\", xticklabels=\"\", yticklabels=\"\")\n",
    "g.despine(top=True, right=True, left=True, bottom=True)\n",
    "g.ax.margins(0.02)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"icc_obs_controls.pdf\")\n",
    "\n",
    "nodes_strength = sig_icc_case.sum(axis=0)\n",
    "threshold = np.percentile(nodes_strength, 75)\n",
    "len_nonzero_nodes = len(nodes_strength[nodes_strength > 0])\n",
    "nodes_strength_sorted = np.argsort(nodes_strength)[::-1][:len_nonzero_nodes]\n",
    "nodes_strength_sub = nodes_strength[nodes_strength_sorted]\n",
    "fig, bl_names = plot_4_brains(nodes_strength_sorted, nodes_strength_sub)\n",
    "fig.savefig(Path.cwd().parent / \"figures\" / \"icc_brain_cases_gamma.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picture 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_controls.npy\"\n",
    "icc_obs_controls_alpha = np.load(fname, allow_pickle=True)\n",
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_cases.npy\"\n",
    "icc_obs_cases_alpha = np.load(fname, allow_pickle=True)\n",
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_controls_gamma.npy\"\n",
    "icc_obs_controls_gamma = np.load(fname, allow_pickle=True)\n",
    "fname = Path.cwd().parent / \"data\" / \"icc_obs_cases_gamma.npy\"\n",
    "icc_obs_cases_gamma = np.load(fname, allow_pickle=True)\n",
    "\n",
    "items = [icc_obs_controls_alpha, icc_obs_cases_alpha, icc_obs_controls_gamma, icc_obs_cases_gamma]\n",
    "titles = [\"control_alpha\", \"case_alpha\", \"control_gamma\", \"case_gamma\"]\n",
    "\n",
    "## plotting the ICC matrixes\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "for item, title in zip(items, titles): \n",
    "    df_icc = pd.DataFrame(item).stack().reset_index()\n",
    "    df_icc.rename(columns={\"level_0\" : \"lb-1\", \"level_1\": \"lb-2\", 0: \"ICC-val\"}, inplace=True)\n",
    "\n",
    "    pal = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    g = sns.relplot(data=df_icc, x=\"lb-1\", y=\"lb-2\", hue=\"ICC-val\",\n",
    "                    palette=pal, hue_norm=(0, 1), sizes=(1, 1), legend=False,\n",
    "                    height=5, aspect=1)\n",
    "    g.ax.invert_yaxis()\n",
    "    g.set(xlabel=\"\", ylabel=\"\", xticklabels=\"\", yticklabels=\"\")\n",
    "    g.despine(top=True, right=True, left=True, bottom=True)\n",
    "    g.ax.margins(0.02)\n",
    "    g.tight_layout()\n",
    "    g.savefig(Path.cwd().parent / \"figures\" / f\"icc_{title}.pdf\")\n",
    "\n",
    "## plot the nodal strength\n",
    "for item, title in zip(items[3:4], titles[3:4]):\n",
    "    nodes_strength = item.sum(axis=0)\n",
    "    threshold = np.percentile(nodes_strength, 75)\n",
    "    len_nonzero_nodes = len(nodes_strength[nodes_strength > threshold])\n",
    "    nodes_strength_sorted = np.argsort(nodes_strength)[::-1][:len_nonzero_nodes]\n",
    "    nodes_strength_sub = nodes_strength[nodes_strength_sorted]\n",
    "    fig, bl_names = plot_4_brains(nodes_strength_sorted, nodes_strength_sub)\n",
    "    # fig.savefig(Path.cwd().parent / \"figures\" / f\"icc_brain_{title}.pdf\")\n",
    "\n",
    "## plot the distributions\n",
    "my_dict = {}\n",
    "n_edges = 68\n",
    "mask = np.triu(np.ones((n_edges, n_edges), dtype=bool), k=1)\n",
    "my_dict[\"icc_values\"] = np.concatenate([items[0][mask], items[1][mask], items[2][mask], items[3][mask]], axis=0)\n",
    "my_dict[\"group\"] = mask.sum() * [\"controls\"] + mask.sum() * [\"cases\"] + mask.sum() * [\"controls\"] + mask.sum() * [\"cases\"]\n",
    "my_dict[\"frequency\"] = mask.sum() * [\"alpha\"] * 2 + mask.sum() * [\"gamma\"] * 2\n",
    "df = pd.DataFrame(my_dict)\n",
    "\n",
    "g = sns.FacetGrid(data=df, col=\"frequency\", height=3, aspect=1.5, xlim=[0, 1], legend_out=False)\n",
    "pal = ['#1f77b4', '#d62728']\n",
    "kwargs = {\"x\": \"icc_values\", \"hue\": \"group\", \"stat\": \"percent\", \"linewidth\": 0.2,\n",
    "            \"palette\": pal, \"fill\": True, \"edgecolor\": \"k\"}\n",
    "g.map_dataframe(sns.histplot, line_kws={\"lw\": 6}, **kwargs)\n",
    "legend_data = {\"control\": mpatches.Patch(color=pal[0]), \"case\": mpatches.Patch(color=pal[1])} \n",
    "g.add_legend(legend_data=legend_data, frameon=False)\n",
    "g.tight_layout()\n",
    "g.savefig(Path.cwd().parent / \"figures\" / \"icc_dist.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality check fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {\"freq_band\": [], \"label_1\": [], \"label_2\": [], \"group\": [], \"connection_strength\": []}\n",
    "\n",
    "brain_labels = mne.read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=False)[:-1]\n",
    "\n",
    "for freq_range in [\"theta\", \"alpha\", \"gamma\"]:\n",
    "    ## check normality\n",
    "    dir1 = '/Users/payamsadeghishabestari/meg_gsp/stc_labels/tinmeg1'\n",
    "    dir2 = '/Users/payamsadeghishabestari/meg_gsp/stc_labels/tinmeg3'\n",
    "    fnames = []\n",
    "    for dir in [dir1, dir2]:\n",
    "        for filename in sorted(os.listdir(dir)): \n",
    "            f = os.path.join(dir, filename)\n",
    "            if os.path.isfile(f) and f.endswith(f'aparc_mean.npy') and freq_range in f:\n",
    "                fnames.append(f)\n",
    "\n",
    "    n_controls = 23\n",
    "    sfreq = 250\n",
    "    end_sample = 5 * 60 * sfreq \n",
    "    kwargs = {\n",
    "            \"dist_type\": \"sqeuclidean\",\n",
    "            \"alpha\": 1,\n",
    "            \"step\": 0.5,\n",
    "            \"maxit\": 10000,\n",
    "            \"rtol\": 1e-16,\n",
    "            \"beta\": 1,\n",
    "            \"w0\": None,\n",
    "            \"retall\": False\n",
    "            }\n",
    "\n",
    "    graphs = []\n",
    "    for fname in tqdm(fnames):\n",
    "        tcs = np.load(file=fname, allow_pickle=True)[:, :end_sample]\n",
    "        graph = learn_graph.log_degree_barrier(X=tcs, **kwargs)\n",
    "        graph = graph / np.linalg.norm(graph, 'fro')\n",
    "        graphs.append(graph)\n",
    "\n",
    "    graphs_control = np.array(graphs[:n_controls]) # the shape should be (23, 2, 68, 68)\n",
    "    graphs_cases = np.array(graphs[n_controls:])\n",
    "    n_edges = graphs_control.shape[-1]\n",
    "\n",
    "    mask = np.triu(np.ones((n_edges, n_edges), dtype=bool), k=1)\n",
    "    up_tri_idxs = np.triu_indices(n_edges, k=1)\n",
    "    controls_upper = graphs_control[:, mask]\n",
    "    cases_upper = graphs_cases[:, mask]\n",
    "\n",
    "    pvals = []\n",
    "    for i in range(controls_upper.shape[1]):\n",
    "        _, p_val_control = shapiro(controls_upper[:, i])\n",
    "        _, p_val_case = shapiro(cases_upper[:, i])\n",
    "\n",
    "        if p_val_control < 0.05 or p_val_case < 0.05:\n",
    "            stat, p_val = mannwhitneyu(controls_upper[:, i], cases_upper[:, i])\n",
    "        \n",
    "        else:\n",
    "            stat, p_val = ttest_ind(controls_upper[:, i], cases_upper[:, i])\n",
    "\n",
    "        pvals.append(p_val)\n",
    "\n",
    "    reject_null, p_corrected, _, _ = sm.stats.multipletests(pvals=pvals, alpha=0.05,\n",
    "                                                                method=\"fdr_bh\")\n",
    "\n",
    "    label_idxs = []\n",
    "    if len(np.where(p_corrected < 0.05)[0]) == 0:\n",
    "        print(f\"No statistical difference between brain labels for method\")\n",
    "    else:\n",
    "        for idx in np.where(p_corrected < 0.05)[0]:\n",
    "            label_idxs.append((up_tri_idxs[0][idx], up_tri_idxs[1][idx]))\n",
    "            idx_1 = up_tri_idxs[0][idx]\n",
    "            idx_2 = up_tri_idxs[1][idx]\n",
    "\n",
    "            for subject in graphs_control:\n",
    "                conn = subject[idx_1][idx_2]\n",
    "\n",
    "                my_dict[\"freq_band\"].append(freq_range)\n",
    "                my_dict[\"label_1\"].append(brain_labels[idx_1].name)\n",
    "                my_dict[\"label_2\"].append(brain_labels[idx_2].name)\n",
    "                my_dict[\"group\"].append(\"control\")\n",
    "                my_dict[\"connection_strength\"].append(conn)\n",
    "\n",
    "            for subject in graphs_cases:\n",
    "                conn = subject[idx_1][idx_2]\n",
    "\n",
    "                my_dict[\"freq_band\"].append(freq_range)\n",
    "                my_dict[\"label_1\"].append(brain_labels[idx_1].name)\n",
    "                my_dict[\"label_2\"].append(brain_labels[idx_2].name)\n",
    "                my_dict[\"group\"].append(\"case\")\n",
    "                my_dict[\"connection_strength\"].append(conn)\n",
    "                \n",
    "df_1 = pd.DataFrame(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting the boxplots\n",
    "fname = Path.cwd().parent / \"data\" / \"stat_comp.csv\"\n",
    "df = pd.read_csv(fname)\n",
    "df[\"labels_together\"] = df[\"label_1\"] + \" & \" + df[\"label_2\"]\n",
    "df_theta = df.query('freq_band == \"theta\"')\n",
    "df_alpha = df.query('freq_band == \"alpha\"')\n",
    "df_gamma = df.query('freq_band == \"gamma\"')\n",
    "palette_color = ['#1f77b4', '#d62728'] \n",
    "hue_order = [\"control\", \"case\"]\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(5.5, 8))\n",
    "\n",
    "box_kwargs = {\"width\": .8, \"gap\": 0.3, \"linewidth\": 1.5}\n",
    "size = 4\n",
    "sns.boxplot(data=df_theta, x=\"labels_together\", y=\"connection_strength\", hue=\"group\", \n",
    "            hue_order=hue_order, palette=palette_color, fill=False, ax=axs[0], legend=False, **box_kwargs)\n",
    "sns.stripplot(data=df_theta, x=\"labels_together\", y=\"connection_strength\", hue=\"group\", dodge=True,\n",
    "                hue_order=hue_order, palette=palette_color, size=size,\n",
    "                edgecolor=None, ax=axs[0], legend=False)\n",
    "\n",
    "\n",
    "box_kwargs = {\"width\": 0.8, \"gap\": 0.3, \"linewidth\": 1.4}\n",
    "size = 2.8\n",
    "sns.boxplot(data=df_alpha, x=\"labels_together\", y=\"connection_strength\", hue=\"group\", \n",
    "            hue_order=hue_order, palette=palette_color, fill=False, ax=axs[1], legend=False, **box_kwargs)\n",
    "sns.stripplot(data=df_alpha, x=\"labels_together\", y=\"connection_strength\", hue=\"group\", dodge=True,\n",
    "                hue_order=hue_order, palette=palette_color, size=size,\n",
    "                edgecolor=None, ax=axs[1], legend=False)\n",
    "\n",
    "box_kwargs = {\"width\": 0.8, \"gap\": 0.3, \"linewidth\": 1.3}\n",
    "size = 2.4\n",
    "\n",
    "sns.boxplot(data=df_gamma, x=\"labels_together\", y=\"connection_strength\", hue=\"group\", \n",
    "            hue_order=hue_order, palette=palette_color, fill=False, ax=axs[2], legend=False, **box_kwargs)\n",
    "sns.stripplot(data=df_gamma, x=\"labels_together\", y=\"connection_strength\", hue=\"group\", dodge=True,\n",
    "                hue_order=hue_order, palette=palette_color, size=size,\n",
    "                edgecolor=None, ax=axs[2], legend=False)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=4)\n",
    "    ax.set_ylim([-0.005, 0.04])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(Path.cwd().parent / \"figures\" / f\"new_boxplots.pdf\")\n",
    "\n",
    "## plotting the glass brains\n",
    "def plot_glass_brains(df, title):\n",
    "    ###### fig 3_C ######\n",
    "    labels = mne.read_labels_from_annot(subject='fsaverage', parc='aparc', subjects_dir=None, verbose=False)[:-1]\n",
    "    node_coords = []\n",
    "    for label in labels:\n",
    "        if label.hemi == 'lh':\n",
    "            hemi = 0\n",
    "        if label.hemi == 'rh':\n",
    "            hemi = 1\n",
    "        center_vertex = label.center_of_mass(subject='fsaverage', \n",
    "                                            restrict_vertices=False, \n",
    "                                            subjects_dir=None)\n",
    "        mni_pos = mne.vertex_to_mni(center_vertex, hemis=hemi,\n",
    "                                subject='fsaverage', subjects_dir=None)\n",
    "        node_coords.append(mni_pos)\n",
    "    node_coords = np.array(node_coords)\n",
    "    ticks = [lb.name for lb in labels]\n",
    "    matrix = np.zeros(shape=(len(labels), len(labels)))\n",
    "    \n",
    "    for lb in df[\"labels_together\"].unique():\n",
    "        print(lb)\n",
    "        df_1 = df.query(f'labels_together == \"{lb}\"')\n",
    "        idx1 = ticks.index(df_1[\"label_1\"].unique()[0])\n",
    "        idx2 = ticks.index(df_1[\"label_2\"].unique()[0])\n",
    "            \n",
    "            \n",
    "        matrix[idx1][idx2] = 1 \n",
    "\n",
    "    graph = matrix + matrix.T\n",
    "    custom_cmap = sns.cubehelix_palette(10, rot=-.45, light=.65, reverse=True, as_cmap=True)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(11, 3))\n",
    "    edge_kwargs = {\"lw\": 3}\n",
    "    plot_connectome(adjacency_matrix=graph, node_coords=node_coords, display_mode=\"lzry\", edge_cmap=custom_cmap,\n",
    "                    node_color='k', node_size=10, axes=ax, colorbar=False,\n",
    "                    edge_threshold=\"90%\", edge_kwargs=edge_kwargs)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(Path.cwd().parent / \"figures\" / f\"new_{title}_glass_brain_green.pdf\")\n",
    "\n",
    "for sub_dfs, title in zip([df_theta, df_alpha, df_gamma][2:3], [\"theta\", \"alpha\", \"gamma\"][2:3]):\n",
    "    plot_glass_brains(sub_dfs, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"fusiform-rh\", \"bankssts-rh\", \"cuneus-lh\", \"lateraloccipital-lh\",\n",
    "                \"paracentral-rh\", \"precentral-lh\", \"inferiorparietal-lh\",\n",
    "                \"precuneus-lh\", \"insula-lh\", \"parahippocampal-lh\",\n",
    "                \"lateralorbitofrontal-lh\", \"transversetemporal-lh\",\n",
    "                \"superiorfrontal-lh\", \"superiorfrontal-rh\",\n",
    "                \"bankssts-lh\", \"parsorbitalis-lh\", \"frontalpole-lh\",\n",
    "                \"frontalpole-rh\", \"paracentral-lh\",\n",
    "                \"superiorparietal-lh\"][4:5]\n",
    "\n",
    "brain_labels = np.array(mne.read_labels_from_annot(subject=\"fsaverage\", parc=\"aparc\", verbose=False))\n",
    "lb_names = [lb.name for lb in brain_labels]\n",
    "idxs = np.array([lb_names.index(lb) for lb in label_names])\n",
    "lbs = list(brain_labels[idxs])\n",
    "cl1 = sns.cubehelix_palette(10, rot=2.5, light=.7, reverse=True)[9]\n",
    "cl2 = sns.cubehelix_palette(10, rot=-2*np.pi/10, light=.7, reverse=True)[1]\n",
    "cl3 = sns.cubehelix_palette(10, rot=4.5, light=.7, reverse=True)[3]\n",
    "cl4 = list(sns.color_palette(\"Reds\")[-1])\n",
    "cl5 = sns.cubehelix_palette(10, rot=4.5, light=.7, reverse=True)[2]\n",
    "cl6 = sns.cubehelix_palette(10, rot=8.5, light=.7, reverse=True)[8]\n",
    "cl7 = sns.cubehelix_palette(10, rot=8.5, light=.7, reverse=True)[0]\n",
    "cl8 = sns.cubehelix_palette(10, rot=1.5, light=.7, reverse=True)[2]\n",
    "cl9 = sns.cubehelix_palette(10, rot=4.5, light=.7, reverse=True)[5]\n",
    "cl10 = sns.diverging_palette(100, 20, as_cmap=False, n=10)[1]\n",
    "cl11 = sns.diverging_palette(100, 20, as_cmap=False, n=10)[5]\n",
    "cl12 = sns.diverging_palette(100, 20, as_cmap=False, n=10)[9]\n",
    "cl13 = sns.diverging_palette(180, 60, as_cmap=False, n=10)[0]\n",
    "cl14 = sns.diverging_palette(180, 60, as_cmap=False, n=10)[4]\n",
    "cl15 = sns.diverging_palette(180, 60, as_cmap=False, n=10)[7]\n",
    "cl16 = sns.diverging_palette(290, 10, as_cmap=False, n=10)[2]\n",
    "cl17 = sns.diverging_palette(290, 10, as_cmap=False, n=10)[5]\n",
    "cl18 = sns.diverging_palette(290, 10, as_cmap=False, n=10)[8]\n",
    "cl19 = sns.color_palette(\"icefire\", as_cmap=False, n_colors=10)[1]\n",
    "cl20 = sns.color_palette(\"icefire\", as_cmap=False, n_colors=10)[3]\n",
    "cl21 = sns.color_palette(\"icefire\", as_cmap=False, n_colors=10)[8]\n",
    "\n",
    "colors = [cl1, cl2, cl3, cl4, cl5, cl6, cl7, cl8, cl9, cl10, cl11, cl12, cl13, cl14, cl15, cl16, cl17, cl18, cl19, cl20, cl21]\n",
    "\n",
    "brain_kwargs = dict(background=\"white\", surf=\"pial_semi_inflated\", cortex=[\"#b8b4ac\", \"#b8b4ac\"])\n",
    "\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"lh\", views=\"lateral\", **brain_kwargs)\n",
    "for lb, color in zip(lbs, colors):\n",
    "    if lb.hemi == \"lh\":\n",
    "        brain.add_label(lb, hemi=\"lh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "brain_scr_1 = brain.screenshot()\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"rh\", views=\"lateral\", **brain_kwargs)\n",
    "for lb, color in zip(lbs, colors):\n",
    "    if lb.hemi == \"rh\":\n",
    "        brain_scr_2 = brain.add_label(lb, hemi=\"rh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "brain_scr_2 = brain.screenshot()\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"lh\", views=\"medial\", **brain_kwargs)\n",
    "for lb, color in zip(lbs, colors):\n",
    "    if lb.hemi == \"lh\":\n",
    "        brain_scr_3 = brain.add_label(lb, hemi=\"lh\", color=color, borders=False, alpha=0.7)\n",
    "\n",
    "brain_scr_3 = brain.screenshot()\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"rh\", views=\"medial\", **brain_kwargs)\n",
    "for lb, color in zip(lbs, colors):\n",
    "    if lb.hemi == \"rh\":\n",
    "        brain_scr_4 = brain.add_label(lb, hemi=\"rh\", color=color, borders=False, alpha=0.7)\n",
    "        \n",
    "brain_scr_4 = brain.screenshot()\n",
    "\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"both\", views=\"rostral\", **brain_kwargs)\n",
    "for lb, color in zip(lbs, colors):\n",
    "        brain_scr_5 = brain.add_label(lb, hemi=\"both\", color=color, borders=False, alpha=0.7)\n",
    "        \n",
    "brain_scr_5 = brain.screenshot()\n",
    "\n",
    "brain = mne.viz.Brain(\"fsaverage\", subjects_dir=None, hemi=\"both\", views=\"caudal\", **brain_kwargs)\n",
    "for lb, color in zip(lbs, colors):\n",
    "        brain_scr_6 = brain.add_label(lb, hemi=\"both\", color=color, borders=False, alpha=0.7)\n",
    "        \n",
    "brain_scr_6 = brain.screenshot()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(9, 7))\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "for ax, brain in zip([axes[0][0], axes[0][1], axes[1][0], axes[1][1]], [brain_scr_1, brain_scr_2, brain_scr_3, brain_scr_4]):\n",
    "    nonwhite_pix = (brain != 255).any(-1)\n",
    "    nonwhite_row = nonwhite_pix.any(1)\n",
    "    nonwhite_col = nonwhite_pix.any(0)\n",
    "    cropped_screenshot = brain[nonwhite_row][:, nonwhite_col]\n",
    "    ax.imshow(cropped_screenshot)\n",
    "    ax.axis(\"off\")\n",
    "# fig.savefig(Path.cwd().parent / \"figures\" / \"brains_aparc_new.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
